---
title: Load to a data warehouse
description: Load OpenAlex JSON data into BigQuery, Snowflake, or other data warehouses
---

In a data warehouse, you can load the OpenAlex JSON entities directly and query them with native JSON functions — no schema flattening required. This guide uses [BigQuery](https://cloud.google.com/bigquery) as an example.

<Info>
**Snowflake users:** A ready-to-query dataset is available on the Snowflake Marketplace, maintained by [Util](https://www.util.co/) — [OpenAlex on Snowflake Marketplace](https://app.snowflake.com/marketplace/listing/GZT0ZOMX4O7).
</Info>

<Info>
Community-contributed loading scripts (not tested by us, but may be helpful):
- [naustica/openalex](https://github.com/naustica/openalex) — BigQuery loader
- [DrorSh/openalex_to_gbq](https://github.com/DrorSh/openalex_to_gbq) — BigQuery loader
</Info>

## Prerequisites

- The [snapshot downloaded](/download/download-to-machine) to your machine
- [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) installed
- A Google account with permissions to create BigQuery tables

## Step 1: Create a project and dataset

Create a BigQuery [Project](https://cloud.google.com/resource-manager/docs/creating-managing-projects) and [Dataset](https://cloud.google.com/bigquery/docs/datasets-intro):

```bash
bq mk openalex-demo:openalex
```

## Step 2: Create tables for each entity type

Since we're loading raw JSON, each table has a single text column:

```bash
bq mk --table openalex-demo:openalex.works work:string
bq mk --table openalex-demo:openalex.authors author:string
bq mk --table openalex-demo:openalex.sources source:string
bq mk --table openalex-demo:openalex.institutions institution:string
bq mk --table openalex-demo:openalex.topics topic:string
bq mk --table openalex-demo:openalex.publishers publisher:string
bq mk --table openalex-demo:openalex.funders funder:string
```

## Step 3: Load the data files

Load each table from the JSON Lines files. Here's a single file load:

```bash
bq load \
  --project_id openalex-demo \
  --source_format=CSV -F '\t' \
  --schema 'work:string' \
  openalex.works \
  'openalex-snapshot/data/works/updated_date=2024-01-15/0000_part_00.gz'
```

<Note>
The `--source_format=CSV -F '\t' --schema 'work:string'` trick tells BigQuery to treat each line as a single text column by using tab as a delimiter (which doesn't appear in the data).
</Note>

The real dataset has many files, so use a loop:

```bash
for data_file in openalex-snapshot/data/works/*/*.gz;
do
    bq load --source_format=CSV -F '\t' \
        --schema 'work:string' \
        --project_id openalex-demo \
        openalex.works $data_file;
done
```

Repeat for each entity type, substituting the entity name.

<Warning>
This step is slow — hours, not minutes for Works and Authors. You can speed it up with [`parallel`](https://www.gnu.org/software/parallel/), but watch for [BigQuery quota](https://cloud.google.com/bigquery/docs/troubleshoot-quotas) limits.
</Warning>

## Step 4: Run queries

Query the data using [BigQuery JSON functions](https://cloud.google.com/bigquery/docs/reference/standard-sql/json_functions):

**Simple: Extract work IDs and OA status**

```sql
SELECT
    json_value(work, '$.id') AS work_id,
    json_value(work, '$.open_access.is_oa') AS is_oa
FROM
    `openalex-demo.openalex.works`;
```

**Advanced: Find the author with the most open access works**

```sql
WITH work_authorships_oa AS (
    SELECT
        json_value(work, '$.id') AS work_id,
        json_query_array(work, '$.authorships') AS authorships,
        CAST(json_value(work, '$.open_access.is_oa') AS BOOL) AS is_oa
    FROM `openalex-demo.openalex.works`
),
flat_authorships AS (
    SELECT work_id, authorship, is_oa
    FROM work_authorships_oa,
    UNNEST(authorships) AS authorship
)
SELECT
    json_value(authorship, '$.author.id') AS author_id,
    COUNT(DISTINCT work_id) AS num_oa_works
FROM flat_authorships
WHERE is_oa
GROUP BY author_id
ORDER BY num_oa_works DESC
LIMIT 10;
```

You can run queries from the shell or use the BigQuery [console](https://console.cloud.google.com/bigquery):

```bash
bq query \
  --project_id=openalex-demo \
  --use_legacy_sql=false \
  "SELECT json_value(work, '$.id') AS work_id FROM openalex.works LIMIT 10;"
```
